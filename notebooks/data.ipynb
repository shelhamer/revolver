{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Data is handled by `Datasets` in the `revolver.data` module.\n",
    "\n",
    "- `revolver.data.seg` defines the base segmentation dataset interface and masking datasets that load mask-wise instead of image-wise.\n",
    "- `revolver.data.pascal` has datasets for VOC/SBDD semantic and instance segmentation.\n",
    "- `revolver.data.sparse` has a wrapper for static and dynamic sparse targets.\n",
    "- `revolver.data.filter` has wrappers for filtering and mapping targets.\n",
    "\n",
    "The wrappers are compositional so that a given kind of data can be loaded by composing a base dataset with the necessary wrappers. This notebook illustrates common use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "from revolver.data.pascal import VOCSemSeg, VOCInstSeg, SBDDSemSeg, SBDDInstSeg\n",
    "from revolver.data.seg import MaskSemSeg, MaskInstSeg\n",
    "from revolver.data.sparse import SparseSeg\n",
    "from revolver.data.filter import TargetFilter, TargetMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch the working dir to the project root to align notebook usage with the rest of the code. (The project root is found through git.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "root_dir = subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip()\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataset and have a first look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the default dataset root dir works on its own if invoked from the root dir of the project,\n",
    "# and this call gives the path only as an illustration.\n",
    "ds = VOCSemSeg(root_dir='./data/voc2012')  \n",
    "print(\"Dataset with {} images in split {} and {} classes:\\n{}\".format(len(ds), ds.split, ds.num_classes, ds.classes))\n",
    "\n",
    "# all datasets return a 3-tuple with image, target/label, and auxiliary dictionary\n",
    "# note: image and target are np arrays unless they are cast by transforms\n",
    "im, target, aux = ds[0]  \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"item ID {}\".format(ds.slugs[0]))\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "# plot the target class-by-class\n",
    "# in the next step we'll make this simpler and prettier with a palette to color the classes\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(target == ds.classes.index('aeroplane'))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(target == ds.classes.index('person'))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(target == ds.ignore_index)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done that let's make a helper to inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_and_show(ds, title, count=1, print_aux=True):\n",
    "    for i in range(count):\n",
    "        im, target, aux = ds[np.random.randint(0, len(ds))]\n",
    "        im = Image.fromarray(im, mode='RGB')\n",
    "        target = Image.fromarray(target, mode='P')\n",
    "        target.putpalette(ds.palette)  # plot with pretty colors\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        if print_aux:\n",
    "            figtitle = title + \" \" + str(aux)\n",
    "        plt.title(title)\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(target)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading semantic and instance segmentation data from VOC and its extended annotations in SBDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = VOCSemSeg()  # default split is train\n",
    "load_and_show(ds, \"VOC semantic segmentation\")\n",
    "\n",
    "ds = SBDDSemSeg(split='train')\n",
    "load_and_show(ds, \"SBDD semantic segmentation\")\n",
    "\n",
    "ds = VOCInstSeg(split='val')\n",
    "load_and_show(ds, \"VOC instance segmentation\")\n",
    "\n",
    "ds = SBDDInstSeg()\n",
    "load_and_show(ds, \"SBDD instance segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking decomposes the dataset over masks instead of images. Indexing mask-wise instead of image-wise makes it possible to sample fairly over all masks whether they are class or instance masks. Were the indexing over images, first sampling an image and then sampling a mask would sample masks inversely proportionally to the number of masks in the image.\n",
    "\n",
    "These datasets return the **binary** segmentation of a single mask as the target along with class and instance indices in the auxiliary dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = MaskSemSeg(VOCSemSeg())\n",
    "load_and_show(ds, \"VOC class masks\", count=3)\n",
    "\n",
    "# instance masking requires both a semantic seg. and an instance seg. dataset\n",
    "# to preserve class information\n",
    "ds = MaskInstSeg(VOCSemSeg(), VOCInstSeg())\n",
    "load_and_show(ds, \"VOC instance masks\", count=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity makes targets that are spatially sparse. The `SparseSeg` wrapper takes a count and limits every target value, whether class or instance, to that many points. The sparsity can be dynamic (the default), and sampled on every load, or static, and sampled once and for all on init to simulate a fixed sparse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reduce masks to 100 points per class, resampled on every load\n",
    "ds = VOCSemSeg()\n",
    "ds = SparseSeg(ds, count=100)\n",
    "load_and_show(ds, \"sparse VOC semantic segmentation\", count=3)\n",
    "\n",
    "# reduce masks to a fixed 16 points per class\n",
    "# re-loading does not choose new points\n",
    "ds = VOCSemSeg()\n",
    "ds = SparseSeg(ds, count=16, static=True)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"static sparsity\")\n",
    "im, target, aux = ds[0]\n",
    "plt.imshow(target)\n",
    "plt.subplot(1, 2, 2)\n",
    "im, target, aux = ds[0]\n",
    "plt.imshow(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering and mapping restricts and transforms targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter classes to only load images that include the filtered classes\n",
    "ds = VOCSemSeg()\n",
    "classes_to_filter = (ds.classes.index('aeroplane'), ds.classes.index('train'), ds.classes.index('car'))\n",
    "ds_filtered = TargetFilter(ds, classes_to_filter)\n",
    "load_and_show(ds_filtered, \"Planes, Trains, and Automobiles\", count=3)\n",
    "\n",
    "# filter classes to only load images that include the filtered classes, and exclude other classes from the target\n",
    "ds_mapped = TargetMapper(ds_filtered, {k: k in classes_to_filter for k in range(len(ds.classes))})\n",
    "load_and_show(ds_mapped, \"Planes, Trains, and Automobiles ONLY\", count=3, print_aux=False)\n",
    "\n",
    "# collapse all classes to make foreground/background target \n",
    "ds_fgbg = TargetMapper(ds, {k: 1 for k in range(1, ds.num_classes + 1)})\n",
    "load_and_show(ds_fgbg, \"FG/BG\", count=3, print_aux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's combine the datasets and wrappers to make sparse instance masks of cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = MaskInstSeg(VOCSemSeg(), VOCInstSeg())\n",
    "ds = TargetFilter(ds, (ds.classes.index('cat'),))\n",
    "ds = SparseSeg(ds, count=128)\n",
    "load_and_show(ds, \"sparse cat instance masks\", count=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Datasets`, including compositional datasets that inherit from the `Wrapper` mixin such as the masking datasets, can be cached by pickling/unpickling. This can save a lot of time, as long as care is taken to fully decide the name for the cache file. Try running the cell below and compare it to the timing of the original instantiation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_path = 'notebooks/ds-cache.pkl'\n",
    "\n",
    "pickle.dump(ds, open(cache_path, 'wb'))\n",
    "del ds\n",
    "\n",
    "ds = pickle.load(open(cache_path, 'rb'))\n",
    "os.remove(cache_path)\n",
    "\n",
    "load_and_show(ds, \"sparse cat instance masks, cached\", count=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
